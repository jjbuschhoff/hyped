from __future__ import annotations
from abc import ABC, abstractmethod
from datasets import Features
from dataclasses import dataclass
from collections import defaultdict
from hyped.base.config import BaseConfig, BaseConfigurable
from types import GeneratorType
from typing import Literal, Any, TypeVar, Generator


@dataclass
class BaseDataProcessorConfig(BaseConfig):
    """Base Data Processor Config

    Attributes:
        keep_input_features (bool):
            whether to pipe input features to output or only output
            features generted by the data processor
    """

    t: Literal["hyped.data.processor.base"] = "hyped.data.processor.base"
    # attributes
    keep_input_features: bool = True


T = TypeVar("T", bound=BaseDataProcessorConfig)


class BaseDataProcessor(BaseConfigurable[T], ABC):
    """Abstract Base Data Processor

    Provides basic functionality of a data-processor. Sub-types need to
    specify the `process` and `map_features` function.

    Arguments:
        config (BaseDataProcessorConfig): data processor configuration
    """

    def __init__(self, config: BaseDataProcessorConfig) -> None:
        self._config = config
        self._in_features: Features = None
        self._new_features: Features = None

    @classmethod
    def from_config(cls, config: BaseDataProcessorConfig) -> BaseDataProcessor:
        """Instantiate data processor from the given config

        Arguments:
            config (BaseDataProcessorConfig): data processor configuration
        """
        return cls(config)

    @property
    def config(self) -> BaseDataProcessorConfig:
        """Get the processor configuration

        Returns:
            config (BaseDataProcessorConfig): config
        """
        return self._config

    @property
    def is_prepared(self) -> bool:
        """Check if the processor is prepared and ready for execution

        Returns:
            is_prepared (bool): boolean indicating if the processor is prepared
        """
        return (self._in_features is not None) and (
            self._new_features is not None
        )

    def prepare(self, features: Features) -> Features:
        """Prepare the processor for execution

        Arguments:
            features (Features):
                input dataset features available to the processor on execution

        Returns:
            out_features (Features):
                dataset features of the output of the processor
        """
        # map input features to output features
        # copy as preparation might disturb features inplace
        new_features = self.map_features(features.copy())
        # set features
        self._in_features = features
        self._new_features = new_features
        # return output features
        return self.out_features

    @property
    def in_features(self) -> Features:
        """Input dataset features available to processor

        Returns:
            features (Features): input dataset features
        """
        # check if data processor is prepared
        if not self.is_prepared:
            raise RuntimeError(
                "Data processor not prepared. Did you forget to "
                "call `prepare` before execution?"
            )
        # return features
        return self._in_features

    @property
    def new_features(self) -> Features:
        """New dataset features generated by the processor

        Returns:
            features (Features): new dataset features
        """
        # check if data processor is prepared
        if not self.is_prepared:
            raise RuntimeError(
                "Data processor not prepared. Did you forget to "
                "call `prepare` before execution?"
            )
        # return features
        return self._new_features

    @property
    def out_features(self) -> Features:
        """All output features of the processor. Includes both input
        features and new features generated by the processor. On conflicts,
        the new features are prioritized.

        Returns:
            features (Features): complete output dataset features
        """
        if self.config.keep_input_features:
            return Features(self.in_features | self.new_features)
        else:
            return self.new_features

    def batch_process(
        self,
        examples: dict[str, list[Any]],
        index: list[int],
        rank: int,
        return_index: bool = False,
    ) -> dict[str, list[Any]] | tuple[dict[str, list[Any]], list[int]]:
        """Process a batch of examples

        Arguments:
            examples (dict[str, list[Any]]): batch of examples to process
            index (list[int]): dataset indices of the examples
            rank (int): execution process rank
            return_index (bool):
                whether to return the source index for each output example

        Returns:
            out (dict[str, list[Any]]|tuple[dict[str, list[Any]], list[int]]):
                processed examples and source indices when asked for
        """

        def write_to_out(x, y, keep_x):
            for k, v in (y | x).items():
                out[k].append(v)

        out = defaultdict(list)
        out_index = []
        # process each example one-by-one
        for j, i in enumerate(index):
            x = {k: v[j] for k, v in examples.items()}
            y = self.process(x, index=i, rank=rank)

            # handle output types to to end up with
            # an iterable over outputs
            if isinstance(y, GeneratorType):
                pass
            elif isinstance(y, dict):
                y = (y,)
            else:
                raise ValueError(
                    "Expected output of `DataProcessor.process` to be dict of "
                    "generator of dicts, got %s" % str(y)
                )

            for d in y:
                # merge output with input features if asked for
                d = (x | d) if self.config.keep_input_features else d
                # write all features to output dictionary
                for k, v in d.items():
                    out[k].append(v)
                # add index to out index array
                out_index.append(i)

        # return output examples
        return (out, out_index) if return_index else out

    @abstractmethod
    def process(
        self, example: dict[str, Any], index: int, rank: int
    ) -> dict[str, Any] | Generator[dict[str, Any], None, None]:
        """Abstract process method. Needs to be overwritten in sub-classes.

        The function can either return the output example directly, or it can
        be a generator yielding a number of generated examples. This is handy
        for data augmentation or filtering tasks. An example is filtered out
        when the generator is empty. (i.e. `yield from []`).

        Arguments:
            example (dict[str, Any]): example to process
            index (int): dataset index of the example
            rank (int): execution process rank

        Returns:
            out (dict[str, Any]|Generator[dict[str, Any], None, None]):
                processed example or generator over examples
        """
        ...

    @abstractmethod
    def map_features(self, features: Features) -> Features:
        """Map input features to *new* features. This specifies the exact
        output of the `process` function.

        Arguments:
            features (Features): input dataset features

        Returns:
            out (Features):
                new dataset features. Note that this is not the output feature
                map but only the features generated by the data processor
        """
        ...
